---
title: "Statistical Learning - Data preparation & Supervised Learning"
author: "Angelina Khatiwada, Rijin Baby"
date: "09/06/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Set Information:

This data was collected via a survey on Amazon Mechanical Turk. The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver.

- Multivariate dataset
- Number of Instances: 12684
- Number of Attributes: 23
- Associated Tasks: Classification
- Missing Values: Yes


## Some Attribute Information:

- expiration: 1d, 2h (the coupon expires in 1 day or in 2 hours)
- Bar: never, less1, 1~3, gt8, nan4~8 (feature meaning: how many times do you go to a bar every month?)
- CoffeeHouse: never, less1, 4~8, 1~3, gt8, nan (feature meaning: how many times do you go to a coffeehouse every month?)
- CarryAway:n4~8, 1~3, gt8, less1, never (feature meaning: how many times do you get take-away food every month?)
- RestaurantLessThan20: 4~8, 1~3, less1, gt8, never (feature meaning: how many times do you go to a restaurant with an average expense per person of less than $20 every month?)
- Restaurant20To50: 1~3, less1, never, gt8, 4~8, nan (feature meaning: how many times do you go to a restaurant with average expense per person of $20 - $50 every month?)
- toCoupon_GEQ15min:0,1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 15 minutes)
- toCoupon_GEQ25min:0, 1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 25 minutes)
- direction_same:0, 1 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)
- direction_opp:1, 0 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)
- Y:1, 0 (whether the coupon is accepted)

```{r message=FALSE, warning=FALSE}
    library(skimr)
    library(readr)
    library(plyr)
    library(dplyr)
    library(purrr)
    library(VIM)
    library(ggplot2)
    library(plotly)
    library(caret)
    library(grid)
    library(gridExtra)
    library("epitools")
    library(pROC)
    library(MASS)
    library(class)
    library(gmodels)

```

## Dataset
```{r message=FALSE, warning=FALSE}
  in_vehicle_coupon_recommendation <- read_csv("https://raw.githubusercontent.com/rijinbaby/Statistical-Learning/main/in-vehicle-coupon-recommendation.csv")
  coupon_data <- in_vehicle_coupon_recommendation
  coupon_data <- as.data.frame(coupon_data)
  
  library(purrr)
  # View(coupon_data %>% map(table))
  coupon_data %>% map(table)
```
### Missing & unique value check
```{r}
  (colMeans(is.na(coupon_data))*100)
  coupon_data$car <- NULL # no data at all - 4 other with <2% missing
  
  which(apply(coupon_data, 2, function(x) length(unique(x)))==1)
  coupon_data$toCoupon_GEQ5min <- NULL # removing column with single value
```
```{r}
coupon_accepted <- as.factor(coupon_data$Y)

#age
t1 <- ggplot(coupon_data, aes(x=age, fill=coupon_accepted)) +
    geom_bar(stat="count")

#income 
t2 <- ggplot(coupon_data, aes(x=income, fill=coupon_accepted)) +
  geom_bar(stat="count")

#expiration
t3 <- ggplot(coupon_data, aes(x=expiration, fill=coupon_accepted)) +
  geom_bar(stat="count")

grid.arrange(t1, t2, t3, ncol=1)

```


### New Variables
```{r message=FALSE, warning=FALSE}
{
  coupon_data[] <- lapply(coupon_data, as.character)
  #coupon_data$Y <- as.numeric(coupon_data$Y)
  coupon_data$Y <- as.factor(coupon_data$Y)
  
  # age column - Creating a new column to give numerical weightage
  #table(coupon_data$age)
  #coupon_data$age_weightage <- NA
  #coupon_data$age_weightage[which(coupon_data$age=="below21")] <- 1
  #coupon_data$age_weightage[which(coupon_data$age=="21")] <- 2
  #coupon_data$age_weightage[which(coupon_data$age=="26")] <- 3
  #coupon_data$age_weightage[which(coupon_data$age=="31")] <- 4
  #coupon_data$age_weightage[which(coupon_data$age=="36")] <- 5
  #coupon_data$age_weightage[which(coupon_data$age=="41")] <- 6
  #coupon_data$age_weightage[which(coupon_data$age=="46")] <- 7
  #coupon_data$age_weightage[which(coupon_data$age=="50plus")] <- 8
  #table(coupon_data$age_weightage)
  
  # temp & weather
  # View(table(coupon_data$weather,coupon_data$temperature))
  
  # Income - Creating a new column to give numerical weightage
  #table(coupon_data$income)
  #coupon_data$income_weightage <- NA
  #coupon_data$income_weightage[which(coupon_data$income=="Less than $12500")] <- 1
  #coupon_data$income_weightage[which(coupon_data$income=="$12500 - $24999")] <- 2
  #coupon_data$income_weightage[which(coupon_data$income=="$25000 - $37499")] <- 3
  #coupon_data$income_weightage[which(coupon_data$income=="$37500 - $49999")] <- 4
  #coupon_data$income_weightage[which(coupon_data$income=="$50000 - $62499")] <- 5
  #coupon_data$income_weightage[which(coupon_data$income=="$62500 - $74999")] <- 6
  #coupon_data$income_weightage[which(coupon_data$income=="$75000 - $87499")] <- 7
  #coupon_data$income_weightage[which(coupon_data$income=="$87500 - $99999")] <- 8
  #coupon_data$income_weightage[which(coupon_data$income=="$100000 or More")] <- 9
  #table(coupon_data$income_weightage)
  
  # Occupation - Creating a new column to re-classify reference - https://en.wikipedia.org/wiki/International_Standard_Classification_of_Occupations
  (table(coupon_data$occupation))
  coupon_data$occupation_class <- NA
  coupon_data$occupation_class[which(coupon_data$occupation %in% 
                                       c("Architecture & Engineering","Arts Design Entertainment Sports & Media"
                                         ,"Business & Financial","Computer & Mathematical","Education&Training&Library"
                                         ,"Healthcare Practitioners & Technical","Legal","Management"))] <- "Professionals"
  coupon_data$occupation_class[which(coupon_data$occupation %in% 
                                       c("Building & Grounds Cleaning & Maintenance","Food Preparation & Serving Related"
                                         ,"Installation Maintenance & Repair","Transportation & Material Moving"))]  <- "Craft and related trades workers"
  coupon_data$occupation_class[which(coupon_data$occupation %in% 
                                       c("Community & Social Services","Construction & Extraction","Healthcare Support"
                                         ,"Life Physical Social Science"))] <- "Technicians and pro"
  coupon_data$occupation_class[which(coupon_data$occupation %in% 
                                       c("Personal Care & Service","Protective Service","Sales & Related"))] <- "Service and sales"
  coupon_data$occupation_class[which(coupon_data$occupation %in% 
                                       c("Farming Fishing & Forestry","Office & Administrative Support"
                                         ,"Production Occupations"))] <- "Others"  #own classification
  coupon_data$occupation_class[which(coupon_data$occupation=="Retired")] <- 'Retired' 
  coupon_data$occupation_class[which(coupon_data$occupation=="Student")] <- "Student"
  coupon_data$occupation_class[which(coupon_data$occupation=="Unemployed")] <- "Unemployed"
  
  occup_class <- coupon_data %>%
  group_by(occupation_class) %>%
  summarise("Actual_occupation" = occupation)
  occup_class <- unique(occup_class)
 
                                       
  # TIME VARIABLE
  table(coupon_data$expiration)
  coupon_data$expiration_weightage <- NA
  coupon_data$expiration_weightage[which(coupon_data$expiration=="2h")] <- 2
  coupon_data$expiration_weightage[which(coupon_data$expiration=="1d")] <- 24
  coupon_data$expiration_weightage <- scale(as.numeric(coupon_data$expiration_weightage), center = FALSE)
  
  # passenger
  coupon_data$passanger[which(coupon_data$passanger=="Friend(s)")] <- "Friends"
  coupon_data$passanger[which(coupon_data$passanger=="Kid(s)")] <- "Kids"
  
  # education
  coupon_data$education[which(coupon_data$education=="Graduate degree (Masters or Doctorate)")] <- "Graduate degree"
  # print(table(coupon_data$occupation_class))
  
}
```
```{r}
 
knitr::kable(occup_class, format = "html")
```

### missing imputation knn approach
```{r}
  library(VIM)
  # colMeans(is.na(coupon_data))*100
  # which(colMeans(is.na(coupon_data))>0)
  cleaned_data <- kNN(coupon_data
                           , variable = c("Bar","CoffeeHouse","CarryAway","RestaurantLessThan20","Restaurant20To50")
                           , k = 5)
  cleaned_data <- cleaned_data[,1:ncol(coupon_data)]
  # coupon_data_final %>% map(table)
  colMeans(is.na(cleaned_data))*100
```
### Plotting data


```{r message=FALSE, warning=FALSE}
library(gridExtra)


#Destination
p1 <- ggplot(cleaned_data, aes(x=destination, fill=Y)) +
    geom_bar(stat="count")

#passanger 
p2 <- ggplot(cleaned_data, aes(x=passanger, fill=Y)) +
  geom_bar(stat="count")

#weather
p3 <- ggplot(cleaned_data, aes(x=weather, fill=Y)) +
  geom_bar(stat="count")

#time
p4 <- ggplot(cleaned_data, aes(x=time, fill=Y)) +
  geom_bar(stat="count")

#gender
p5 <- ggplot(cleaned_data, aes(x=gender, fill=Y)) +
  geom_bar(stat="count")

#maritalStatus   
p6 <- ggplot(cleaned_data, aes(x=maritalStatus, fill=Y)) +
  geom_bar(stat="count")+
  theme(axis.text.x = element_text(angle = 15, hjust = 1))

grid.arrange(p1, p2, p3, p4, p5, p6, ncol=2)

```

```{r}
#education                       
p7 <- ggplot(cleaned_data, aes(x=education, fill=Y)) +
  geom_bar(stat="count")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
p7

#occupation                                          
p8 <- ggplot(cleaned_data, aes(x=occupation_class, fill=Y)) +
  geom_bar(stat="count")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
p8

```

```{r}
#Bar                                                 
p9 <- ggplot(cleaned_data, aes(x=Bar, fill=Y)) +
  geom_bar(stat="count")

#CoffeeHouse                                       
p10 <- ggplot(cleaned_data, aes(x=CoffeeHouse, fill=Y)) +
  geom_bar(stat="count")

#CarryAway                       
p11 <- ggplot(cleaned_data, aes(x=CarryAway, fill=Y)) +
  geom_bar(stat="count")

#RestaurantLessThan20                                
p12 <- ggplot(cleaned_data, aes(x=RestaurantLessThan20, fill=Y)) +
  geom_bar(stat="count")

#direction_same                                               
p13 <- ggplot(cleaned_data, aes(x=direction_same, fill=Y)) +
  geom_bar(stat="count")

#has_children                                                
p14 <- ggplot(cleaned_data, aes(x=has_children, fill=Y)) +
  geom_bar(stat="count")

grid.arrange(p9, p10, p11, p12, p13, p14, ncol=2)

```


**For numeric variables**
```{r}
#Age histogram
#p15 <- ggplot(data = cleaned_data, aes(age_weightage, color = Y))+
  #geom_freqpoly(binwidth = 5, size = 1)

#Income histogram
#p16 <- ggplot(data = cleaned_data, aes(income_weightage, color = Y))+
  #geom_freqpoly(binwidth = 5, size = 1)

#Expiration histogram
p17 <- ggplot(data = cleaned_data, aes(expiration_weightage, color = Y))+
  geom_freqpoly(binwidth = 5, size = 1)

p17
```

## Modeling

We drop the variable 'direction_opp' that is perfectly correlated with the varible 'direction_same'.We also drop the categorical varibles 'age', 'income', 'expiration', for which we created corresponding numeric variables. 'occupation' will be replaced by 'occupation_class' in the model.  

- Y - factor
- 'age', 'income', 'expiration' - numeric
- other variables' type is characteric, so the dummies will be created automatically, removing the first dummy variable created from each column. This is done to avoid multicollinearity. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
cleaned_data$Y <- as.factor(cleaned_data$Y)
cleaned_data$has_children <- as.factor(cleaned_data$has_children)
cleaned_data$toCoupon_GEQ15min <- as.factor(cleaned_data$toCoupon_GEQ15min)
cleaned_data$toCoupon_GEQ25min <- as.factor(cleaned_data$toCoupon_GEQ25min)
cleaned_data$direction_same <- as.factor(cleaned_data$direction_same)

drops= c("direction_opp", 'expiration', 'occupation', 'time') #drop additional correlated variables
cleaned_data <- cleaned_data[ , !(colnames(cleaned_data) %in% drops)]

#cleaned_data <- fastDummies::dummy_cols(cleaned_data, remove_first_dummy = TRUE, select_columns ='time')

str(cleaned_data)

```

## Logistic Regression

**Chi-square test** to check the overall effect of variables on the dependent variable

**Multicollinearity check**

Model with all parameters on dataset without splitting

```{r}

full_log_model <- glm(Y ~., data = cleaned_data, family=binomial(link='logit'))
summary(full_log_model)

anova(full_log_model, test = 'Chisq')

car::vif(full_log_model)
```

Insignificant coefficients (with p-value > 0.05) according to chi2 check are:

- has_children
- CarryAway  
- toCoupon_GEQ25min

Porblem of multicollinearity solved. 

## Stepwise Selection

 1) Both directions
```{r}
library(caret)
library(leaps)
library(MASS)
library(caret)

# Fit the both direction model 
step_model <- stepAIC(full_log_model, trace = FALSE)
#summary(step_model)
step_model$anova
```

2) Forward direction
```{r}
# Fit the forward model
forward <- stepAIC(full_log_model, direction = 'forward', trace = FALSE)
#summary(step_model)
forward$anova

```
With forward direction we get the same result as we had with a full model, forward begins with a Null model(intercept only model).

```{r}

# Fit the backward model
backward <- stepAIC(full_log_model, direction = 'backward', trace = FALSE)
#summary(step_model)
backward$anova


```
The backward procedure eliminated exactly the same variables as the “both” procedure.

Different criteria can be assigned to the stepAIC() function for stepwise selection. The default is AIC, which is performed by assigning the argument k to 2 (default).

We tried running bestglm, but there is a hard-coded constraint in bestglm (15 predictors means there are 2^15 = 32768 candidate models). In our case we have around 70 variables counting dummies.

```{r eval=FALSE, include=FALSE}
library(leaps)
library(bestglm)
args(bestglm)
```


```{r eval=FALSE, include=FALSE}
coupon_data_encoded = cleaned_data

coupon_data_encoded$Y <- as.numeric(cleaned_data$Y)
coupon_data_encoded$has_children <- as.numeric(coupon_data_encoded$has_children)
coupon_data_encoded$toCoupon_GEQ15min <- as.numeric(coupon_data_encoded$toCoupon_GEQ15min)
coupon_data_encoded$toCoupon_GEQ25min <- as.numeric(coupon_data_encoded$toCoupon_GEQ25min)
coupon_data_encoded$direction_same <- as.numeric(coupon_data_encoded$direction_same)

encoded <- fastDummies::dummy_cols(coupon_data_encoded, remove_first_dummy = TRUE)
  
coupon_data_encoded <- encoded[ , ((!(colnames(encoded) %in% colnames(coupon_data_encoded))) 
                                     | (colnames(encoded) %in% c("Y" ,"expiration_weightage", 'has_children', 'toCoupon_GEQ15min', 'toCoupon_GEQ25min', 'direction_same' )))]
  
```

```{r eval=FALSE, include=FALSE}
bestglm(coupon_data_encoded, IC ='BIC', family = binomial)
```

## Running 10 fold Cross-Validation on Full and Stepwise model using training data

Initially split in train and test sets to avoid overfitting

```{r}
set.seed(123)
split_train_test  <- createDataPartition(cleaned_data$Y, p = .67,list = FALSE, times = 1)
 
train <- cleaned_data[ split_train_test,]
test  <- cleaned_data[-split_train_test,]


#CV  with 10 folds on full model
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
log_reg_full <- train(Y ~.,
               data = train,
               trControl = train_control,
               method = "glm",
               family=binomial(link='logit')) 

log_reg_full 
#summary(log_reg_full)


#CV  with 10 folds on step model
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
log_reg_step <- train(Y ~.,
               data=subset(train, select=c( -CarryAway, -RestaurantLessThan20)),
               trControl = train_control,
               method = "glm",
               family=binomial(link='logit'))

log_reg_step
#summary(log_reg_step)

```
Full model AIC: 10138
Stepwise model AIC: 10134

According to the bias-variance trade-off, all things equal, simpler model should be always preferred because it is less likely to overfit the training data.

### Predictions

**Model accuracy and Confusion matrix**

**FULL  MODEL**
```{r}
log_reg_prob1 <- predict(log_reg_full, test, type = 'prob')
log_reg_pred1 <- ifelse(log_reg_prob1[2] > 0.5, 1, 0)
mean(log_reg_pred1 == test$Y)
```

**STEP  MODEL**
```{r}
log_reg_prob1 <- predict(log_reg_step, test, type = 'prob')
log_reg_pred1 <- ifelse(log_reg_prob1[2] > 0.5, 1, 0)
mean(log_reg_pred1 == test$Y)
```

```{r}
confusionMatrix(
  as.factor(log_reg_pred1),
  as.factor(test$Y),
  positive = "1" 
)
```

High sensitivity: fewer False Negative errors. Low specificity: Many False Positive.

We can change the threshold 0.5 to balance these values.
Focus on sensitivity - more importance for business opportunities

```{r}
log_reg_pred1 <- ifelse(log_reg_prob1[2] > 0.45, 1, 0)

confusionMatrix(
  as.factor(log_reg_pred1),
  as.factor(test$Y),
  positive = "1" 
)
```

**ROC curve**
```{r}
test_roc = roc(test$Y ~ log_reg_prob1$"1", plot = TRUE, print.auc = TRUE)
```
## Lasso and Elastic Net

With dummy variables we have 70 variables, some of the coefficients are already shrinked.
We tried to apply Lasso and Elastic Net to find a reduced set of variables resulting to an optimal performing mode lusing Penalized logistic regression (penalty for having too many variables - regularization).

lasso regression: the coefficients of some less contributive variables are forced to be exactly zero. Only the most significant variables are kept in the final model.

elastic net regression: the combination of ridge and lasso regression. It shrinks some coefficients toward zero (like ridge regression) and set some coefficients to exactly zero.

```{r}
library(glmnet)

set.seed(123)

x=model.matrix(Y~., data=train)[,-20]
y=as.numeric(train$Y)

x.test <- model.matrix(Y ~., test)[,-20]

fit.lasso= glmnet(x, y, family = "binomial", alpha = 1) #lambda = NULL
plot(fit.lasso,xvar="lambda",label=TRUE)

cv.lasso=cv.glmnet(x, y, family = "binomial", alpha = 1)
plot(cv.lasso)
cv.lasso$lambda.min

```
Cross-validation error according to the log of lambda. Vertical line indicates that the log of the optimal value of lambda is around -7, which is the one that minimizes the prediction error (higher accuracy)

The purpose of regularization is to balance accuracy and simplicity. 

```{r}
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1, lambda = cv.lasso$lambda.min) #lambda = NULL
# Display regression coefficients
coef(lasso_model)
```


```{r}
#Make predictions on the test data

probabilities <- lasso_model %>% predict(x.test)
predicted.classes <- ifelse(probabilities > 0.5, "1", "0")
#Model accuracy
observed.classes <- test$Y
mean(predicted.classes == observed.classes)
```

Results eliminating 2 variables do not show improvement in the the model performance on the test data.

**ELASTIC NET**

For elastic net regression, alpha is between 0 and 1. 

We automatically select the best tuning parameters alpha and lambda 

```{r}
lambda <- 10^seq(-3, 3, length = 100)
```


```{r}
# Build the model
set.seed(123)
elastic <- train(
  Y ~., data = train, method = "glmnet",
  family = "binomial",
  trControl = trainControl("cv", number = 10),
  tuneLength = 5
  )
# Best tuning parameter
elastic$bestTune
```
```{r}
elastic_model <- glmnet(x, y, family = "binomial", alpha = elastic$bestTune$alpha, lambda = elastic$bestTune$lambda) #lambda = NULL
# Display regression coefficients
coef(lasso_model)

#Make predictions on the test data

probabilities <- elastic_model %>% predict(x.test)
predicted.classes <- ifelse(probabilities > 0.5, "1", "0")
#Model accuracy
observed.classes <- test$Y
mean(predicted.classes == observed.classes)
```

Elastic Net performs a bit better than Lasso.


## Linear Discriminant Analysis

```{r}
lda.fit=lda(Y~.,data = train)
lda.fit

plot(lda.fit)
```

```{r}
lda.pred=predict(lda.fit,test)$class
table(lda.pred,test$Y)
mean(lda.pred==test$Y)
```
LDA predicts more False Positives as well

## Association Rules

We analyse association between Y and the 'direction_same', which is the significant variable

```{r}
assoc <- xtabs(~Y+direction_same, data=cleaned_data)
assoc
plot(assoc, col=c("green","blue"))
```

**Testing significance**
```{r}
Test <- chisq.test(assoc, correct=FALSE)
Test
```

Chi2 is 2.7, relation between the variables is not significant (p-value> 0.05). We accept H0 about independence between the variables, there is no association.

```{r}
riskratio.wald(table(cleaned_data$direction_same,cleaned_data$Y))
oddsratio.wald(table(cleaned_data$direction_same,cleaned_data$Y))

```
Confidence interval includes 1 - accept H0 about independence. 

Odds: odds under direction same/ odds under direction opp = 1.07

```{r}
lr_fit <- glm(Y ~ direction_same, data = cleaned_data,
              family=binomial(link='logit'))
summary(lr_fit)

exp(cbind(OR = coef(lr_fit), confint(lr_fit)))

```
Direction is not a factor.

## KNN model

Uploading a dataset with dummies that are all numeric 

Algorithms which use distance based methods require all variables to be numeric
```{r}

coupon_data_encoded  <- read.csv("https://raw.githubusercontent.com/rijinbaby/Statistical-Learning/main/cleaned_data_encoded.csv")

```

```{r}
##the normalization function is created
nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
coupon_data_encoded[,c("age_weightage","expiration_weightage","income_weightage")] <-
  as.data.frame(lapply(coupon_data_encoded[,c("age_weightage","expiration_weightage","income_weightage")],nor))
```


```{r}
#train/test split

set.seed(123)
split_train_test  <- createDataPartition(coupon_data_encoded$Y, p = .67,
                                  list = FALSE,
                                  times = 1)

train <- coupon_data_encoded[ split_train_test,]
test  <- coupon_data_encoded[-split_train_test,]

train_label <- train$Y
test_label <- test$Y

test$Y <- NULL
train$Y <- NULL


```

**KNN confusion matrix and accuracy for K=10**

```{r}

##run knn function

model_knn <- knn(train = train, test = test ,cl=train_label,k=10)

##create confusion matrix
tab <- table(model_knn,test_label)
tab
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)

CrossTable(x=model_knn, y=test_label, prop.chisq=FALSE) 
```

Check training and test errors for different values of K

```{r}
#loop for different  0<K<21
k <- 1
accuracy_scores_test <- c()
accuracy_scores_train <- c()
k_values <- c()
while (k < 16) {
  k_values <- c(k_values, k)
  test_knn <- knn(train = train, test = test ,cl=train_label,k=k)
  train_knn <- knn(train = train, test = train ,cl=train_label,k=k)
  tab_test <- table(test_knn,test_label)
  tab_train <- table(train_knn,train_label)
  accuracy_scores_test <- c(accuracy_scores_test, accuracy(tab_test))
  accuracy_scores_train <- c(accuracy_scores_train, accuracy(tab_train))
  k = k+1
}

acc = cbind(data.frame(k_values), data.frame(accuracy_scores_test), data.frame(accuracy_scores_train))
acc

```

Plotting accuracy for training (blue) and test sets (red)

```{r}

ggplot(acc, aes(x=k_values)) + 
  geom_line(aes(y = accuracy_scores_test), color = "red", size=1.3) + 
  geom_line(aes(y = accuracy_scores_train), color="blue", size=1.3) 

```


### CLUSTERING

Classify based on the characterisctics and study variations of Y in the groups

```{r}
cleaned_data_clust <- cleaned_data
cleaned_data_clust$ID <- seq.int(nrow(cleaned_data_clust))
cleaned_data_clust<- cleaned_data_clust%>%mutate_if(is.character, as.factor)
str(cleaned_data_clust)
```

Calculating Gower distance as we have mixed type data  (cat and num)

A particular distance metric is used and scaled to fall between 0 and 1 for each variable type. Then Linear combination using user-specified weights is calculated to create the final distance matrix.

**Cons**: Sensitive to non-normality and outliers in cont variables. Requires an NxN distance matrix to be calculated, which is computationally intensive

One possible solution for this is to sample your data, cluster the smaller sample, then treat the clustered sample as training data for k Nearest Neighbors and "classify" the rest of the data.

Create a sample of 500 observations. 

```{r}
set.seed(123) 
sample_clust <- cleaned_data_clust[sample(nrow(cleaned_data_clust), 500),]
```

FUNCTIONS

```{r}
library(cluster)
library(Rtsne)

gower_distance <- function(datafr) {
  
  gower_dist <- daisy(datafr,
                    metric = "gower",
                    type = list(logratio = 3))
# Check attributes to ensure the correct methods are being used
# (I = interval, N = nominal)
  return(gower_dist)
}
```

Clustering for entire driving scenario (with all the variables)
```{r}
set.seed(123) 

#remoxing Y and ID

gower_dist <- gower_distance(sample_clust[,-c(20,23)])
summary(gower_dist)
gower_mat <- as.matrix(gower_dist)

```


```{r}
# Output most similar pair
sample_clust[
  which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]),
        arr.ind = TRUE)[1, ], ]
```

```{r}
# Output most dissimilar pair
sample_clust[
  which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]),
        arr.ind = TRUE)[1, ], ]
```
**K-medoids Clustering**

Partitioning around medoids with custom distance matrix

The k-medoids problem is a clustering problem similar to k-means. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups) and attempt to minimize the distance between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses actual data points as centers (medoids or exemplars), and thereby allows for greater interpretability of the cluster centers than in k-means. Furthermore, k-medoids can be used with arbitrary dissimilarity measures, whereas k-means generally requires Euclidean distance for efficient solutions. Because k-medoids minimizes a sum of pairwise dissimilarities instead of a sum of squared Euclidean distances, it is more robust to noise and outliers than k-means.

Number k of clusters assumed known a priori. The "goodness" of the given value of k can be assessed with methods such as the silhouette method.

Has the added benefit of having an observation serve as the exemplar for each cluster

Selecting the number of clusters using silhouette width, an internal validation metric which is an aggregated measure of how similar an observation is to its own cluster compared its closest neighboring cluster. The metric can range from -1 to 1, where higher values are better.

```{r}
library(Rtsne)

# Calculate silhouette width for many k using PAM
sil_width <- c(NA)
for(i in 2:10){
  
  pam_fit <- pam(gower_dist,
                 diss = TRUE,
                 k = i)
  
  sil_width[i] <- pam_fit$silinfo$avg.width
  
}
# Plot sihouette width (higher is better)
plot(1:10, sil_width,
     xlab = "Number of clusters",
     ylab = "Silhouette Width")
lines(1:10, sil_width)
```
2 clusters show the best result

Interpret the clusters by running summary on each cluster. 
In cluster 1 : No Urgent Place, Friends, Sunny, 80_temp, Coffee House, Male, 21y, Single, 0_has_children
In cluster 2: Alone, Sunny, Married partner, Female, 

```{r}
pam_fit <- pam(gower_dist, diss = TRUE, k = 2)
pam_results <- sample_clust %>%
  dplyr::select(-ID) %>%
  mutate(cluster = pam_fit$clustering) %>%
  group_by(cluster) %>%
  do(the_summary = summary(.))
pam_results$the_summary 
```

```{r}
sample_clust[pam_fit$medoids, ]
```
One way to visualize many variables in a lower dimensional space is with t-distributed stochastic neighborhood embedding, or t-SNE. This method is a (dimensionality reduction technique that tries to preserve local structure so as to make clusters visible in a 2D or 3D visualization). it is able to handle a custom distance metric. 

Plot shows that clusters are overlapping. 

```{r}
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)
tsne_data <- tsne_obj$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering),
         name = sample_clust$ID)
ggplot(aes(x = X, y = Y), data = tsne_data) +
  geom_point(aes(color = cluster))
```
Clusters are overlapping

**Agglomerative clustering**


```{r}
aggl.clust.c <- hclust(gower_dist, method = "complete")
plot(aggl.clust.c,
     main = "Agglomerative, complete linkages")

aggl.clust.c <- hclust(gower_dist, method = "average")
plot(aggl.clust.c,
     main = "Agglomerative, average linkages")

aggl.clust.c <- hclust(gower_dist, method = "single")
plot(aggl.clust.c,
     main = "Agglomerative, single linkages")

aggl.clust.w <- hclust(gower_dist, method = "ward.D2")
plot(aggl.clust.w,
     main = "Agglomerative, ward linkages")



```

```{r}
# hierarchical clustering using Ward linkage

library("reshape2")
library("purrr")
library("dendextend")

dendro <- as.dendrogram(aggl.clust.w)
dendro.col <- dendro %>%
  set("branches_k_color", k = 2, value =   c( "gold3", "darkcyan")) %>%
  set("branches_lwd", 0.6) %>%
  set("labels_colors", 
      value = c("darkslategray")) %>% 
  set("labels_cex", 0.5)
ggd1 <- as.ggdend(dendro.col)
ggplot(ggd1, theme = theme_minimal()) +
  labs(x = "Num. observations", y = "Height", title = "Dendrogram, k = 2")

groups <- cutree(aggl.clust.w, k=2) # cut tree into 5 clusters
```

```{r}
clusplot(sample_clust, groups, color=TRUE, shade=TRUE,
         labels=2, lines=0, main= 'Driving scenario clusters')
```
Questions:
1) How to compare the result with the true labels - Rand index
2) Is the silhouette metrics optimal for evaluation?
3) Should we do a PCA - 18% otf variance explained is very small, more dimensions 
4) explain variabilty of Y within the groups
5) select the number of k in hierarchical clustering to min the dist within the cluster

## Clustering evaluation - Rand index 

## Another startegy - groups based on personal characteristics 

```{r}
sample_clust_pers <- sample_clust[,-c(1:5, 12:19, 22)]
str(sample_clust_pers)

set.seed(123) 

# Remove Y and ID before clustering
gower_dist <- daisy(sample_clust_pers[,-c(7,9)],
                    metric = "gower",
                    type = list(logratio = 3))
# Check attributes to ensure the correct methods are being used
# (I = interval, N = nominal)

summary(gower_dist)

# Calculate silhouette width for many k using PAM
sil_width <- c(NA)
for(i in 2:10){
  
  pam_fit <- pam(gower_dist,
                 diss = TRUE,
                 k = i)
  
  sil_width[i] <- pam_fit$silinfo$avg.width
  
}
# Plot sihouette width (higher is better)
plot(1:10, sil_width,
     xlab = "Number of clusters",
     ylab = "Silhouette Width")
lines(1:10, sil_width)

```

```{r}
pam_fit <- pam(gower_dist, diss = TRUE, k = 2)
pam_results <- sample_clust_pers %>%
  dplyr::select(-ID) %>%
  mutate(cluster = pam_fit$clustering) %>%
  group_by(cluster) %>%
  do(the_summary = summary(.))
#pam_results$the_summary 
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)
tsne_data <- tsne_obj$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering),
         name = sample_clust_pers$ID)
ggplot(aes(x = X, y = Y), data = tsne_data) +
  geom_point(aes(color = cluster))
```
How much variability explained by this 2 components?

Group by characteristics of coupon only

```{r}
sample_clust_coup <- sample_clust[,-c(1:4, 6:16, 19, 21)]
str(sample_clust_coup)

set.seed(123) 

# Remove Y and ID before clustering
gower_dist <- daisy(sample_clust_coup[,-c(3,5)],
                    metric = "gower",
                    type = list(logratio = 3))
# Check attributes to ensure the correct methods are being used
# (I = interval, N = nominal)

summary(gower_dist)

# Calculate silhouette width for many k using PAM
sil_width <- c(NA)
for(i in 2:30){
  
  pam_fit <- pam(gower_dist,
                 diss = TRUE,
                 k = i)
  
  sil_width[i] <- pam_fit$silinfo$avg.width
  
}
# Plot sihouette width (higher is better)
plot(1:30, sil_width,
     xlab = "Number of clusters",
     ylab = "Silhouette Width")
lines(1:30, sil_width)

pam_fit <- pam(gower_dist, diss = TRUE, k = 18)
pam_results <- sample_clust_coup %>%
  dplyr::select(-ID) %>%
  mutate(cluster = pam_fit$clustering) %>%
  group_by(cluster) %>%
  do(the_summary = summary(.))
pam_results$the_summary 

```
```{r}
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)
tsne_data <- tsne_obj$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering),
         name = sample_clust_coup$ID)
ggplot(aes(x = X, y = Y), data = tsne_data) +
  geom_point(aes(color = cluster))
```


<!-- ## one-hot encoding -->
```{r}
  # cleaned_data$age <- NULL; cleaned_data$income <- NULL; cleaned_data$occupation<- NULL; cleaned_data$expiration <- NULL
  # 
  # # library(caret)
  # # dummy <- dummyVars(" ~ .", data=cleaned_data)
  # # coupon_data_encoded <- data.frame(predict(dummy, newdata = cl eaned_data)) 
  # 
  # encoded <- fastDummies::dummy_cols(cleaned_data, remove_first_dummy = TRUE)
  # 
  # coupon_data_encoded <- encoded[ , ((!(colnames(encoded) %in% colnames(cleaned_data))) 
  #                                    | (colnames(encoded) %in% c("Y","age_weightage","income_weightage","expiration_weightage")))]
 

```
<!-- ## PCA -->

```{r}
# newdata_pca <- prcomp(coupon_data_encoded[,-(which(colnames(coupon_data_encoded)=="Y"))], center = TRUE,scale. = TRUE)
# summary(newdata_pca) # need to select PC32 for a cumulative variance of > 80
# newdata_pca$sdev
# View(newdata_pca$rotation)
```


```{r}
```

